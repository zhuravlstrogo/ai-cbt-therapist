# -*- coding: utf-8 -*-
"""
My progress module for viewing user's therapy progress
Provides statistics from exercises and diaries with AI-generated summaries
"""

import os
import json
import hashlib
from datetime import datetime, timedelta
import pandas as pd
from telebot import types
from openrouter import OpenRouterClient
from config import MODEL_SIMPLE, TEMPERATURE, TOP_P, TOP_K

# Set pandas options for better handling of Excel files
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

# Cache for LLM responses (in memory cache with TTL)
llm_cache = {}
CACHE_TTL_HOURS = 24  # Cache for 24 hours


def get_cache_key(user_id, data_type, data_hash):
    """Generate cache key for LLM responses"""
    return f"{user_id}_{data_type}_{data_hash}"


def get_cached_response(cache_key):
    """Get cached LLM response if still valid"""
    if cache_key in llm_cache:
        cached_data = llm_cache[cache_key]
        # Check if cache is still valid
        if datetime.now() - cached_data['timestamp'] < timedelta(hours=CACHE_TTL_HOURS):
            return cached_data['response']
    return None


def set_cached_response(cache_key, response):
    """Store LLM response in cache"""
    llm_cache[cache_key] = {
        'response': response,
        'timestamp': datetime.now()
    }


def count_completed_exercises(user_id):
    """
    Count number of completed exercises for a user
    Returns: tuple (count, list of exercise data)
    """
    try:
        if not os.path.exists('exercises.xlsx'):
            return 0, []

        df = pd.read_excel('exercises.xlsx')

        # Filter by user_id
        user_exercises = df[df['User ID'] == user_id]

        # Group by exercise name and get unique exercises
        if len(user_exercises) > 0:
            # Get unique exercise completions
            exercises_list = []
            for _, row in user_exercises.iterrows():
                exercises_list.append({
                    'name': row.get('Exercise Name', 'Unknown'),
                    'problem': row.get('Problem', ''),
                    'rating': row.get('Problem Rating', 0),
                    'date': row.get('Date Time', ''),
                    'text': row.get('Exercise Text', '')
                })

            # Count unique exercise names
            unique_exercises = user_exercises['Exercise Name'].nunique() if 'Exercise Name' in user_exercises.columns else len(user_exercises)
            return unique_exercises, exercises_list

        return 0, []

    except Exception as e:
        print(f"Error counting exercises: {e}")
        return 0, []


def count_diary_entries(user_id):
    """
    Count number of diary entries for a user
    Returns: tuple (count, list of diary data)
    """
    try:
        if not os.path.exists('diary.xlsx'):
            return 0, []

        df = pd.read_excel('diary.xlsx')

        # Filter by user_id
        user_diaries = df[df['User ID'] == user_id]

        if len(user_diaries) > 0:
            diaries_list = []
            for _, row in user_diaries.iterrows():
                diaries_list.append({
                    'type': row.get('Entry Type', 'Unknown'),
                    'text': row.get('Entry Text', ''),
                    'date': row.get('Date Time', '')
                })

            return len(user_diaries), diaries_list

        return 0, []

    except Exception as e:
        print(f"Error counting diary entries: {e}")
        return 0, []


def generate_diary_summary(diary_data, user_problems=None, user_id=None):
    """
    Generate summary of diary entries using LLM
    """
    try:
        if not diary_data:
            return "–ü–æ–∫–∞ –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π –≤ –¥–Ω–µ–≤–Ω–∏–∫–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        # Create data hash for caching (include problems in hash for personalization)
        cache_data = {
            'data': diary_data,
            'problems': user_problems or []
        }
        data_str = json.dumps(cache_data, ensure_ascii=False, sort_keys=True)
        data_hash = hashlib.md5(data_str.encode()).hexdigest()[:8]
        cache_key = get_cache_key(user_id or 'unknown', 'diary_summary', data_hash)

        # Check cache
        cached = get_cached_response(cache_key)
        if cached:
            print(f"Using cached diary summary for user {user_id}")
            return cached

        # Prepare diary entries for analysis
        entries_text = ""
        for entry in diary_data:
            date_str = entry.get('date', '–ë–µ–∑ –¥–∞—Ç—ã')
            if isinstance(date_str, pd.Timestamp):
                date_str = date_str.strftime('%d.%m.%Y')
            entries_text += f"\n- {date_str}: [{entry.get('type', '')}] {entry.get('text', '')}"

        problems_text = ""
        if user_problems:
            problems_text = f"–ò–∑–Ω–∞—á–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∫–ª–∏–µ–Ω—Ç–∞: {', '.join(user_problems)}\n\n"

        system_prompt = """–¢—ã –æ–ø—ã—Ç–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥ –ø–æ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ-–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–æ–π —Ç–µ—Ä–∞–ø–∏–∏ —Å 15-–ª–µ—Ç–Ω–∏–º —Å—Ç–∞–∂–µ–º.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–Ω–µ–≤–Ω–∏–∫–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ –∫–ª–∏–µ–Ω—Ç–∞ –∏ –¥–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏.

–í–∞–∂–Ω–æ:
- –û—Ç—Ä–∞–∂–∞–π –∏ –≤–∞–ª–∏–¥–∏—Ä—É–π –ø–µ—Ä–µ–∂–∏–≤–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞
- –ù–æ—Ä–º–∞–ª–∏–∑—É–π –±–µ–∑ –æ–±–µ—Å—Ü–µ–Ω–∏–≤–∞–Ω–∏—è
- –ë—É–¥—å —ç–º–ø–∞—Ç–∏—á–Ω—ã–º –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º
- –û—Ç–º–µ—á–∞–π –ø–æ–∑–∏—Ç–∏–≤–Ω—É—é –¥–∏–Ω–∞–º–∏–∫—É, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
- –§–æ—Ä–º—É–ª–∏—Ä—É–π –∫—Ä–∞—Ç–∫–æ (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"""

        user_prompt = f"""{problems_text}–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–Ω–µ–≤–Ω–∏–∫–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ –∫–ª–∏–µ–Ω—Ç–∞:
{entries_text}

–û—Ü–µ–Ω–∏:
1. –î–∏–Ω–∞–º–∏–∫—É —Å–æ—Å—Ç–æ—è–Ω–∏—è (—É–ª—É—á—à–µ–Ω–∏–µ/—Å—Ç–∞–±–∏–ª—å–Ω–æ/—É—Ö—É–¥—à–µ–Ω–∏–µ)
2. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
3. –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É –∑–∞–ø–∏—Å–µ–π
4. –ü—Ä–æ–≥—Ä–µ—Å—Å –≤ —Ä–∞–±–æ—Ç–µ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏

–î–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), –æ—Ç—Ä–∞–∂–∞—è –∏ –≤–∞–ª–∏–¥–∏—Ä—É—è –ø–µ—Ä–µ–∂–∏–≤–∞–Ω–∏—è."""

        client = OpenRouterClient()
        response, usage = client.get_simple_response(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            model=MODEL_SIMPLE,
            temperature=TEMPERATURE,
            top_p=TOP_P,
            top_k=TOP_K
        )

        # Cache the response
        set_cached_response(cache_key, response.strip())
        print(f"Cached diary summary for user {user_id}")

        return response.strip()

    except Exception as e:
        print(f"Error generating diary summary: {e}")
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –¥–Ω–µ–≤–Ω–∏–∫–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π."


def generate_exercise_summary(exercise_data, user_id=None):
    """
    Generate summary of completed exercises using LLM
    """
    try:
        if not exercise_data:
            return "–ü–æ–∫–∞ –Ω–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        # Create data hash for caching
        data_str = json.dumps(exercise_data, ensure_ascii=False, sort_keys=True)
        data_hash = hashlib.md5(data_str.encode()).hexdigest()[:8]
        cache_key = get_cache_key(user_id or 'unknown', 'exercise_summary', data_hash)

        # Check cache
        cached = get_cached_response(cache_key)
        if cached:
            print(f"Using cached exercise summary for user {user_id}")
            return cached

        # Prepare exercise data for analysis
        exercises_text = ""
        for ex in exercise_data:
            date_str = ex.get('date', '–ë–µ–∑ –¥–∞—Ç—ã')
            if isinstance(date_str, pd.Timestamp):
                date_str = date_str.strftime('%d.%m.%Y')
            exercises_text += f"\n- {date_str}: {ex.get('name', '–£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ')} –¥–ª—è –ø—Ä–æ–±–ª–µ–º—ã '{ex.get('problem', '')}' (–≤–∞–∂–Ω–æ—Å—Ç—å: {ex.get('rating', 0)}/3)"

        system_prompt = """–¢—ã –æ–ø—ã—Ç–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥ –ø–æ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ-–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–æ–π —Ç–µ—Ä–∞–ø–∏–∏ —Å 15-–ª–µ—Ç–Ω–∏–º —Å—Ç–∞–∂–µ–º.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–æ–º —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –∏ –¥–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏.

–í–∞–∂–Ω–æ:
- –ü–æ–¥—á–µ—Ä–∫–∏–≤–∞–π –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –∏ —É—Å–∏–ª–∏—è –∫–ª–∏–µ–Ω—Ç–∞
- –û—Ç–º–µ—á–∞–π –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–æ—Ü–µ—Å—Å
- –ë—É–¥—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º –∏ –º–æ—Ç–∏–≤–∏—Ä—É—é—â–∏–º
- –§–æ—Ä–º—É–ª–∏—Ä—É–π –∫—Ä–∞—Ç–∫–æ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"""

        user_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è:
{exercises_text}

–û—Ü–µ–Ω–∏:
1. –†–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
2. –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø—Ä–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ç–µ–º
3. –í–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–æ—Ü–µ—Å—Å —Ç–µ—Ä–∞–ø–∏–∏

–î–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞—è —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è."""

        client = OpenRouterClient()
        response, usage = client.get_simple_response(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            model=MODEL_SIMPLE,
            temperature=TEMPERATURE,
            top_p=TOP_P,
            top_k=TOP_K
        )

        # Cache the response
        set_cached_response(cache_key, response.strip())
        print(f"Cached exercise summary for user {user_id}")

        return response.strip()

    except Exception as e:
        print(f"Error generating exercise summary: {e}")
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∞–Ω–∞–ª–∏–∑ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π."


def generate_motivational_phrase(user_name, diary_summary, exercise_summary, stats):
    """
    Generate personalized motivational phrase using LLM
    """
    try:
        # Create data hash for caching
        data_str = f"{user_name}{diary_summary}{exercise_summary}{stats}"
        data_hash = hashlib.md5(data_str.encode()).hexdigest()[:8]
        cache_key = get_cache_key(user_name, 'motivation', data_hash)

        # Check cache (shorter TTL for motivational phrases)
        if cache_key in llm_cache:
            cached_data = llm_cache[cache_key]
            if datetime.now() - cached_data['timestamp'] < timedelta(hours=12):
                return cached_data['response']

        system_prompt = """–¢—ã –æ–ø—ã—Ç–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥ –ø–æ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ-–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–æ–π —Ç–µ—Ä–∞–ø–∏–∏.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Å–æ–∑–¥–∞—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ—Ç–∏–≤–∏—Ä—É—é—â—É—é —Ñ—Ä–∞–∑—É –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ñ—Ä–∞–∑–µ:
- –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è (—É—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–ª–∏–µ–Ω—Ç–∞)
- –ü–æ–∑–∏—Ç–∏–≤–Ω–æ-—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è (–Ω–µ —Ç–æ–∫—Å–∏—á–Ω–æ –ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è)
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∞—è –¥–∞–ª—å–Ω–µ–π—à—É—é —Ä–∞–±–æ—Ç—É
- –ö—Ä–∞—Ç–∫–∞—è (1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –º–∞–∫—Å–∏–º—É–º 15-20 —Å–ª–æ–≤)
- –¢–µ–ø–ª–∞—è –∏ –∏—Å–∫—Ä–µ–Ω–Ω—è—è"""

        context = ""
        if stats['exercises'] > 0 or stats['diaries'] > 0:
            context = f"–ö–ª–∏–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–∏–ª {stats['exercises']} —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π –∏ —Å–¥–µ–ª–∞–ª {stats['diaries']} –∑–∞–ø–∏—Å–µ–π –≤ –¥–Ω–µ–≤–Ω–∏–∫–µ. "

        user_prompt = f"""–ò–º—è –∫–ª–∏–µ–Ω—Ç–∞: {user_name}
{context}
–ê–Ω–∞–ª–∏–∑ –¥–Ω–µ–≤–Ω–∏–∫–∞: {diary_summary}
–ê–Ω–∞–ª–∏–∑ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π: {exercise_summary}

–°–æ–∑–¥–∞–π –æ–¥–Ω—É –∫–æ—Ä–æ—Ç–∫—É—é –º–æ—Ç–∏–≤–∏—Ä—É—é—â—É—é —Ñ—Ä–∞–∑—É (1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ), –∫–æ—Ç–æ—Ä–∞—è:
- –û—Ç—Ä–∞–∂–∞–µ—Ç —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã
- –ó–≤—É—á–∏—Ç —Ç–µ–ø–ª–æ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ"""

        client = OpenRouterClient()
        response, usage = client.get_simple_response(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            model=MODEL_SIMPLE,
            temperature=TEMPERATURE + 0.2,  # Slightly higher temperature for creativity
            top_p=TOP_P,
            top_k=TOP_K
        )

        # Cache the response
        set_cached_response(cache_key, response.strip())

        return response.strip()

    except Exception as e:
        print(f"Error generating motivational phrase: {e}")
        return "–ö–∞–∂–¥—ã–π —à–∞–≥ –≤–ø–µ—Ä–µ–¥ - —ç—Ç–æ —Ç–≤–æ—è –ø–æ–±–µ–¥–∞, –ø—Ä–æ–¥–æ–ª–∂–∞–π –¥–≤–∏–≥–∞—Ç—å—Å—è –≤ —Å–≤–æ–µ–º —Ç–µ–º–ø–µ."


async def show_my_progress(bot, chat_id, user_id, username):
    """
    Main function to show user's progress
    """
    try:
        # Get user name from greeting states
        from greeting import user_states
        user_name = '–î—Ä—É–≥'
        user_problems = []

        if user_id in user_states:
            user_name = user_states[user_id].get('user_name', '–î—Ä—É–≥')
            user_problems = user_states[user_id].get('problems', [])
        else:
            # Try to get user name from diary.xlsx as fallback (take the latest entry)
            try:
                if os.path.exists('diary.xlsx'):
                    df = pd.read_excel('diary.xlsx')
                    user_rows = df[df['User ID'] == user_id]
                    if len(user_rows) > 0 and 'User Name' in df.columns:
                        # Get the last (most recent) non-empty name
                        for idx in range(len(user_rows) - 1, -1, -1):
                            name_from_diary = user_rows.iloc[idx]['User Name']
                            if pd.notna(name_from_diary) and name_from_diary and name_from_diary != 'User':
                                user_name = name_from_diary
                                print(f"Got user name from diary: {user_name}")
                                break
            except Exception as e:
                print(f"Could not get name from diary: {e}")

        # Count exercises and diaries
        exercise_count, exercise_data = count_completed_exercises(user_id)
        diary_count, diary_data = count_diary_entries(user_id)

        # Prepare statistics
        stats = {
            'exercises': exercise_count,
            'diaries': diary_count
        }

        # STEP 1: Send statistics immediately
        stats_text = f"üìä **–¢–≤–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å, {user_name}**\n\n"
        stats_text += "üìà **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**\n"
        stats_text += f"‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π: {exercise_count}\n"
        stats_text += f"üìñ –ó–∞–ø–∏—Å–µ–π –≤ –¥–Ω–µ–≤–Ω–∏–∫–µ: {diary_count}\n"

        await bot.send_message(
            chat_id,
            stats_text,
            parse_mode='Markdown'
        )

        # STEP 2: Send loading message if there's data to analyze
        if exercise_count > 0 or diary_count > 0:
            loading_text = "–ü—Ä–æ–≤–æ–∂—É –∞–Ω–∞–ª–∏–∑... ‚åõ"
            await bot.send_message(chat_id, loading_text)

            # STEP 3: Generate analysis and send as separate message
            analysis_text = ""

            # Generate summaries only if there is data
            if diary_count > 0:
                analysis_text += "üí≠ **–ê–Ω–∞–ª–∏–∑ –¥–Ω–µ–≤–Ω–∏–∫–∞:**\n"
                diary_summary = generate_diary_summary(diary_data, user_problems, user_id)
                analysis_text += f"{diary_summary}\n\n"
            else:
                diary_summary = ""

            if exercise_count > 0:
                analysis_text += "üéØ **–ê–Ω–∞–ª–∏–∑ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π:**\n"
                exercise_summary = generate_exercise_summary(exercise_data, user_id)
                analysis_text += f"{exercise_summary}\n\n"
            else:
                exercise_summary = ""

            # Generate motivational phrase
            motivational = generate_motivational_phrase(
                user_name,
                diary_summary or "–ù–µ—Ç –∑–∞–ø–∏—Å–µ–π",
                exercise_summary or "–ù–µ—Ç —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π",
                stats
            )
            analysis_text += f"üí™ **–ù–∞–ø—É—Ç—Å—Ç–≤–∏–µ:**\n{motivational}"

            # Add navigation buttons
            markup = types.InlineKeyboardMarkup()
            btn_back = types.InlineKeyboardButton(
                "üîô –ù–∞–∑–∞–¥ –≤ –º–µ–Ω—é",
                callback_data="menu:show"
            )
            markup.add(btn_back)

            # Send analysis with back button
            await bot.send_message(
                chat_id,
                analysis_text,
                reply_markup=markup,
                parse_mode='Markdown'
            )

        else:
            # No data - show starter message with action buttons
            starter_text = "üí™ **–° —á–µ–≥–æ –Ω–∞—á–∞—Ç—å:**\n"
            starter_text += "–ü–æ–ø—Ä–æ–±—É–π –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–µ—Ä–≤–æ–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ –∏–ª–∏ –∑–∞–ø–∏—Å–∞—Ç—å —Å–≤–æ–∏ –º—ã—Å–ª–∏ –≤ –¥–Ω–µ–≤–Ω–∏–∫ - –∫–∞–∂–¥—ã–π –º–∞–ª–µ–Ω—å–∫–∏–π —à–∞–≥ –≤–∞–∂–µ–Ω!"

            markup = types.InlineKeyboardMarkup()

            btn_exercise = types.InlineKeyboardButton(
                "üéØ –í—ã–±—Ä–∞—Ç—å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ",
                callback_data="menu:select_exercise"
            )
            markup.add(btn_exercise)

            btn_diary = types.InlineKeyboardButton(
                "üìù –û—Ç–∫—Ä—ã—Ç—å –¥–Ω–µ–≤–Ω–∏–∫",
                callback_data="menu:diary"
            )
            markup.add(btn_diary)

            btn_back = types.InlineKeyboardButton(
                "üîô –ù–∞–∑–∞–¥ –≤ –º–µ–Ω—é",
                callback_data="menu:show"
            )
            markup.add(btn_back)

            await bot.send_message(
                chat_id,
                starter_text,
                reply_markup=markup,
                parse_mode='Markdown'
            )

    except Exception as e:
        print(f"Error showing progress: {e}")

        # Fallback message
        markup = types.InlineKeyboardMarkup()
        btn_back = types.InlineKeyboardButton(
            "üîô –ù–∞–∑–∞–¥ –≤ –º–µ–Ω—é",
            callback_data="menu:show"
        )
        markup.add(btn_back)

        error_text = "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."
        await bot.send_message(chat_id, error_text, reply_markup=markup)